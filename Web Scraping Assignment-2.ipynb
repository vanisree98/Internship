{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd97cf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hi\\anaconda3\\lib\\site-packages (4.1.3)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.5)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hi\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.7)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hi\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2020.12.5)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hi\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#Let's install the selenium Library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb275ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets noe import all the required libraries \n",
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d07f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect to the web drive\n",
    "\n",
    "driver= webdriver.Chrome(r'C:\\Users\\Hi\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b98e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c84a3f",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f82ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d842956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "job_position=driver.find_element_by_class_name('suggestor-input')\n",
    "job_position.send_keys('Data Analyst')\n",
    "job_location=driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "job_location.send_keys('Bangalore')\n",
    "search_button=driver.find_element_by_class_name('qsbSubmit')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa3a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e425fe87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"52a347cf-aec8-4a78-8009-707c64f7fe32\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"2d456120-50cf-40ca-ad0c-a8c883a2f7da\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"d5abdfcf-016d-4fbe-a8a6-93bb5d301581\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"b4e69dc6-3db7-4984-9158-0bbc757cabd7\")>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the job_tittles\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da81e765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Analyst II',\n",
       " 'Senior Data Analyst II',\n",
       " 'Senior Data Analyst II',\n",
       " 'Data Analysts with Business Analysis',\n",
       " 'Data Analyst / Data Engineer',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr Domain Expert -Data Analysts',\n",
       " 'Business Analyst/Data Analyst',\n",
       " 'Senior Data Analyst - KPO',\n",
       " 'Senior Data Analyst',\n",
       " 'Consultant - Data Analyst']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job title is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d781d0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"88cfc14a-c762-44d1-b652-7083b13f6560\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"1e6610db-ae35-49f9-8290-9d393a0e9a5f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"eb70c0d8-2872-4127-9868-fd68d212bf84\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"dbdc6e7c-fb00-4618-8495-fe537965c62f\")>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the location\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0be89be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Indore, Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job location is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in location_tags:\n",
    "    title=i.text\n",
    "    job_location.append(title)\n",
    "job_location[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b4058c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"00ede973-a055-4d94-a053-d3bb5dc7276f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"5b217b26-8a7e-4a55-ae11-9cd9f4453b1f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"acb16d6c-1420-439b-bb0d-568e34c224cf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"2e15df6f-1167-4e3d-94c4-8f07fcfabea4\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "428201b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerner',\n",
       " 'Flipkart',\n",
       " 'Flipkart',\n",
       " 'Avanze Technologies India Pvt. Ltd.',\n",
       " 'TALENT MAX HR & MANAGEMENT CONSULTANTS',\n",
       " 'Flipkart',\n",
       " 'Siemens',\n",
       " 'Telamon HR Solutions',\n",
       " 'Huquo Consulting Pvt. Ltd',\n",
       " 'Cerner',\n",
       " 'Flipkart']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the company name is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in company_tags:\n",
    "    title=i.text\n",
    "    company_name.append(title)\n",
    "company_name[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e459089e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"7a5ab937-b3b1-44b9-b106-9421b4b641aa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"514e6fb8-03b1-410f-aca4-e1f53ef6fc3c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"e4e6dddb-7f19-41ee-969b-1d84109160ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ab34989e6231afd3cd29a4f5faf05956\", element=\"8212d591-32c7-4fc5-a97b-2beeff60f5e3\")>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract all the tage having  experience required\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "experience_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d119f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6-10 Yrs',\n",
       " '2-4 Yrs',\n",
       " '3-6 Yrs',\n",
       " '6-8 Yrs',\n",
       " '8-13 Yrs',\n",
       " '4-6 Yrs',\n",
       " '0-10 Yrs',\n",
       " '3-5 Yrs',\n",
       " '7-12 Yrs',\n",
       " '8-12 Yrs',\n",
       " '1-3 Yrs']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the experience required is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in experience_tags:\n",
    "    title=i.text\n",
    "    experience_required.append(title)\n",
    "experience_required[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48656c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "#let's checklength of each of list\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0483b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_title\n",
    "jobs['Location']=job_location\n",
    "jobs['Company']=company_name\n",
    "jobs['Experience_required']=experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce9a8bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analysts with Business Analysis</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Avanze Technologies India Pvt. Ltd.</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst / Data Engineer</td>\n",
       "      <td>Indore, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>TALENT MAX HR &amp; MANAGEMENT CONSULTANTS</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Domain Expert -Data Analysts</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>0-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Telamon HR Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst - KPO</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Consultant - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title  \\\n",
       "0                        Data Analyst II   \n",
       "1                 Senior Data Analyst II   \n",
       "2                 Senior Data Analyst II   \n",
       "3   Data Analysts with Business Analysis   \n",
       "4           Data Analyst / Data Engineer   \n",
       "5                    Senior Data Analyst   \n",
       "6        Sr Domain Expert -Data Analysts   \n",
       "7          Business Analyst/Data Analyst   \n",
       "8              Senior Data Analyst - KPO   \n",
       "9                    Senior Data Analyst   \n",
       "10             Consultant - Data Analyst   \n",
       "\n",
       "                                             Location  \\\n",
       "0                                 Bangalore/Bengaluru   \n",
       "1                                 Bangalore/Bengaluru   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4                   Indore, Pune, Bangalore/Bengaluru   \n",
       "5                                 Bangalore/Bengaluru   \n",
       "6                                 Bangalore/Bengaluru   \n",
       "7   Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "8               Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10                                Bangalore/Bengaluru   \n",
       "\n",
       "                                   Company Experience_required  \n",
       "0                                   Cerner            6-10 Yrs  \n",
       "1                                 Flipkart             2-4 Yrs  \n",
       "2                                 Flipkart             3-6 Yrs  \n",
       "3      Avanze Technologies India Pvt. Ltd.             6-8 Yrs  \n",
       "4   TALENT MAX HR & MANAGEMENT CONSULTANTS            8-13 Yrs  \n",
       "5                                 Flipkart             4-6 Yrs  \n",
       "6                                  Siemens            0-10 Yrs  \n",
       "7                     Telamon HR Solutions             3-5 Yrs  \n",
       "8                Huquo Consulting Pvt. Ltd            7-12 Yrs  \n",
       "9                                   Cerner            8-12 Yrs  \n",
       "10                                Flipkart             1-3 Yrs  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jobs[0:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6e6cc3",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c87f4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "17c5723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "job_position=driver.find_element_by_class_name('suggestor-input')\n",
    "job_position.send_keys('Data Scientist ')\n",
    "#finding element for job location bar\n",
    "job_location=driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "job_location.send_keys('Bangalore')\n",
    "#do click using class_name function\n",
    "search_button=driver.find_element_by_class_name('qsbSubmit')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7f484750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for append data create empty list\n",
    "job_title=[]\n",
    "company_name=[]\n",
    "job_location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "14741f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"950ad087-9f9c-4360-8887-10c26f7f5a0d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"dae0ff39-9cef-4acc-a904-25a07163a57e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"d88bbe3f-f549-4c7b-95a4-d14df8da3fdf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"ddf76556-9945-485b-96cf-c882a00337a6\")>]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the job_tittles\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "82e00582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'ASSOCIATE DATA SCIENTIST',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist/Engineer - Global Telecom Setup',\n",
       " 'Analyst- Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job title is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "88b1d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"e7a93f28-bc3a-4056-a55f-8811345fa39a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"2bd0db43-f30d-44c1-9574-818516629f7c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"d84a8652-c653-437a-9e96-6654029c02e5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"96af417d-c0db-4836-b24d-d7f0b0948c36\")>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the location\n",
    "location_tags=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "location_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d03b2eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the job location is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in location_tags:\n",
    "    title=i.text\n",
    "    job_location.append(title)\n",
    "job_location[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4742b931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"6adce0e1-5d45-4908-8a41-02d2cf069049\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"2975a46e-7dd9-47cc-b108-cf57b9cafa16\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"27f84443-c819-4905-b067-45fb16d7d132\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b2d626db59796ebd3105453c9871ee78\", element=\"9a316c3d-1858-4df2-be62-da36445056c0\")>]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SO let's extact all the tags having  the company name\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7119a223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Groww',\n",
       " 'PayU',\n",
       " 'Hinduja Global',\n",
       " 'IBM',\n",
       " 'Applied Materials',\n",
       " 'Applied Materials',\n",
       " 'IBM',\n",
       " 'Applied Materials',\n",
       " 'Global Telecom Setup',\n",
       " 'Sigma Aldrich',\n",
       " 'PayU']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now the text of the company name is inside the tag extracted above.\n",
    "#so we will run a loop over a tag extracted above analysis\n",
    "for i in company_tags:\n",
    "    title=i.text\n",
    "    company_name.append(title)\n",
    "company_name[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f7148aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "#let's checklength of each of list\n",
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0a07f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job_title\n",
    "jobs['Location']=job_location\n",
    "jobs['Company']=company_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "41acd8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Groww</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSOCIATE DATA SCIENTIST</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hinduja Global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/Engineer - Global Telecom Setup</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Global Telecom Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analyst- Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Sigma Aldrich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>Noida, Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Bristlecone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Data Scientist/Data Scientist - Researc...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hexaconcepts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GSK India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Immediate requirement of Data Scientist ( Bang...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Firstsource Solutions Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GSK India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cervello India Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                 Lead Data Scientist   \n",
       "1                               Senior Data Scientist   \n",
       "2                            ASSOCIATE DATA SCIENTIST   \n",
       "3                  Data Scientist: Advanced Analytics   \n",
       "4                                      Data Scientist   \n",
       "5                                      Data Scientist   \n",
       "6             Data Scientist: Artificial Intelligence   \n",
       "7                                      Data Scientist   \n",
       "8      Data Scientist/Engineer - Global Telecom Setup   \n",
       "9                             Analyst- Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11                                     Data Scientist   \n",
       "12                                     Data Scientist   \n",
       "13                 Data Scientist - Immediate Joiners   \n",
       "14                                     Data Scientist   \n",
       "15  Senior Data Scientist/Data Scientist - Researc...   \n",
       "16                                     Data Scientist   \n",
       "17  Immediate requirement of Data Scientist ( Bang...   \n",
       "18                              Senior Data Scientist   \n",
       "19                                     Data Scientist   \n",
       "\n",
       "                                             Location  \\\n",
       "0                                 Bangalore/Bengaluru   \n",
       "1                                 Bangalore/Bengaluru   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4                                 Bangalore/Bengaluru   \n",
       "5                                 Bangalore/Bengaluru   \n",
       "6                                 Bangalore/Bengaluru   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8   Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11                                Bangalore/Bengaluru   \n",
       "12                                Bangalore/Bengaluru   \n",
       "13           Noida, Mumbai, Pune, Bangalore/Bengaluru   \n",
       "14                                Bangalore/Bengaluru   \n",
       "15                                Bangalore/Bengaluru   \n",
       "16                                Bangalore/Bengaluru   \n",
       "17                                Bangalore/Bengaluru   \n",
       "18                                Bangalore/Bengaluru   \n",
       "19                                Bangalore/Bengaluru   \n",
       "\n",
       "                           Company  \n",
       "0                            Groww  \n",
       "1                             PayU  \n",
       "2                   Hinduja Global  \n",
       "3                              IBM  \n",
       "4                Applied Materials  \n",
       "5                Applied Materials  \n",
       "6                              IBM  \n",
       "7                Applied Materials  \n",
       "8             Global Telecom Setup  \n",
       "9                    Sigma Aldrich  \n",
       "10                            PayU  \n",
       "11                            PayU  \n",
       "12                            PayU  \n",
       "13                     Bristlecone  \n",
       "14                            PayU  \n",
       "15                    Hexaconcepts  \n",
       "16                       GSK India  \n",
       "17   Firstsource Solutions Limited  \n",
       "18                       GSK India  \n",
       "19  Cervello India Private Limited  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fd06b",
   "metadata": {},
   "source": [
    "## Q3.You have to use the location and salary filter.You have to scrape data for “Data Scientist” designation for first 10 job results.You have to scrape the job-title, job-location, company name, experience required. The location filter to be used  is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fb37b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get the webpage\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19085ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "job_position=driver.find_element_by_class_name('suggestor-input')\n",
    "job_position.send_keys('Data Scientist ')\n",
    "search_button=driver.find_element_by_class_name('qsbSubmit')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7af84af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter= driver.find_elements_by_xpath(\"//i[@class= 'fleft naukicon naukicon-checkbox']\")\n",
    "salary_filter[3].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8cd9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter= driver.find_elements_by_xpath(\"//i[@class= 'fleft naukicon naukicon-checkbox']\")\n",
    "salary_filter[5].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba84be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title= []\n",
    "job_location= []\n",
    "company_name= []\n",
    "experience_required= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea767d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caec8db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Noida, Greater Noida, Delhi / NCR</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Opening For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Care Health Insurance</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist/ Machine Learning, 2022 Passout...</td>\n",
       "      <td>Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...</td>\n",
       "      <td>Creative Hands HR Consultancy</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Requirement || Data Scientist || Noida</td>\n",
       "      <td>Noida, Delhi / NCR</td>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AM Data Scientist - Goods &amp; Service Tax Networ...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>NISG (National Institute for Smart Government)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>iNICU</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0             Hiring For Senior Data Scientist-Noida   \n",
       "1                         Opening For Data Scientist   \n",
       "2  Data Scientist/ Machine Learning, 2022 Passout...   \n",
       "3                         Data Scientist (freelance)   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6      Urgent Requirement || Data Scientist || Noida   \n",
       "7  AM Data Scientist - Goods & Service Tax Networ...   \n",
       "8                     Data Scientist - MIND Infotech   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        Job location  \\\n",
       "0                  Noida, Greater Noida, Delhi / NCR   \n",
       "1                                   Gurgaon/Gurugram   \n",
       "2  Hyderabad/Secunderabad, Ahmedabad, Chennai, Ba...   \n",
       "3                                   New Delhi, Delhi   \n",
       "4                                 Gurgaon, Bengaluru   \n",
       "5                                          New Delhi   \n",
       "6                                 Noida, Delhi / NCR   \n",
       "7                                        Delhi / NCR   \n",
       "8                                              Noida   \n",
       "9                                              Delhi   \n",
       "\n",
       "                                     Company Name Experience Required  \n",
       "0                                        Lumiq.ai             2-6 Yrs  \n",
       "1                           Care Health Insurance             1-5 Yrs  \n",
       "2                   Creative Hands HR Consultancy             0-4 Yrs  \n",
       "3                                           2Coms             2-7 Yrs  \n",
       "4                                       BlackBuck             3-7 Yrs  \n",
       "5                         Boston Consulting Group             2-5 Yrs  \n",
       "6                                HCL Technologies             3-8 Yrs  \n",
       "7  NISG (National Institute for Smart Government)             3-8 Yrs  \n",
       "8        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs  \n",
       "9                                           iNICU             1-5 Yrs  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title= []\n",
    "job_location= []\n",
    "company_name= []\n",
    "experience_required= []\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class= 'title fw500 ellipsis']\"):\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//li[@class= 'fleft grey-text br2 placeHolderLi location']/span\"):\n",
    "    job_location.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class= 'subTitle ellipsis fleft']\"):\n",
    "    company_name.append(i.text)\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//li[@class= 'fleft grey-text br2 placeHolderLi experience']/span\"):\n",
    "    experience_required.append(i.text)\n",
    "dictionnary = {\n",
    "   'Job title': job_title[:10], \n",
    "   'Job location':job_location[:10], \n",
    "   'Company Name':company_name[:10], \n",
    "   'Experience Required':experience_required[:10]\n",
    "}\n",
    "jobs = pd.DataFrame(data=dictionnary) \n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc16c2a",
   "metadata": {},
   "source": [
    "## Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1725430",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "#let's open the webpage through over web driver \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62b5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "cross.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27754874",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "description = []\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52aa8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "# Creating object of the search bar by finding it through Class name\n",
    "search_bar_fk=driver.find_element_by_class_name('_3704LK')\n",
    "\n",
    "# Clearing the bar if there is any text in it\n",
    "search_bar_fk.clear()\n",
    "\n",
    "# Sending required product to the search bar\n",
    "search_bar_fk.send_keys('Sunglasses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebddbc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object of the search button and sending click commamnd\n",
    "search_button = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()\n",
    "time.sleep(3) # pausing the code for 3 seconds, allowing page to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "780be798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹295</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ZOSTAL</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹188</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Mirrored, Gradient Round Sungla...</td>\n",
       "      <td>₹253</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hipe</td>\n",
       "      <td>UV Protection, Gradient, Mirrored, Riding Glas...</td>\n",
       "      <td>₹233</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Round Sungl...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (50)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                        Description Price  \\\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹379   \n",
       "1           PIRASO              UV Protection Aviator Sunglasses (54)  ₹249   \n",
       "2        Elligator                UV Protection Round Sunglasses (54)  ₹295   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "4           SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...  ₹273   \n",
       "..             ...                                                ...   ...   \n",
       "95          ZOSTAL  UV Protection, Polarized Rectangular Sunglasse...  ₹188   \n",
       "96       Rich Club  UV Protection, Mirrored, Gradient Round Sungla...  ₹253   \n",
       "97            hipe  UV Protection, Gradient, Mirrored, Riding Glas...  ₹233   \n",
       "98          SUNBEE  UV Protection, Polarized, Mirrored Round Sungl...  ₹314   \n",
       "99          PIRASO              UV Protection Aviator Sunglasses (50)  ₹349   \n",
       "\n",
       "   Discount  \n",
       "0   81% off  \n",
       "1   84% off  \n",
       "2   88% off  \n",
       "3   20% off  \n",
       "4   78% off  \n",
       "..      ...  \n",
       "95  81% off  \n",
       "96  68% off  \n",
       "97  76% off  \n",
       "98  81% off  \n",
       "99  78% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a in range (3):\n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    desc_tags = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]//a')\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    discount_tags = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]//span')\n",
    "\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    for i in desc_tags:\n",
    "        description.append(i.text)\n",
    "    \n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "\n",
    "    if (a < 1):\n",
    "        nxt = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "        nxt.click()\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        nxt = driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"][2]')\n",
    "        nxt.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "desc = description[0::2]\n",
    "sunglasses = pd.DataFrame({})\n",
    "sunglasses['Brand Name'] = brand\n",
    "sunglasses['Description'] = desc\n",
    "sunglasses['Price'] = price\n",
    "sunglasses['Discount'] = discount\n",
    "sunglasses = sunglasses[:100]\n",
    "sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5fea6",
   "metadata": {},
   "source": [
    "## Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11- black-64-gb-includes-  earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09bece70",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace'\n",
    "#let's open the webpage through over web driver \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df9cebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')\n",
    "driver.find_element_by_xpath(\"//div[@class= '_3UAT2v _16PBlm']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae92a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef19419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Just go for it.\\nThis phone is really amazing....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>A wort full value for money decision it’s . Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>A perfect phone and a good battery super camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I've used this phone for over a month now and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Excellent camera 📸 And Display touching very N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5              Brilliant   \n",
       "1       5         Simply awesome   \n",
       "2       5    Best in the market!   \n",
       "3       5       Perfect product!   \n",
       "4       5              Fabulous!   \n",
       "..    ...                    ...   \n",
       "95      4              Excellent   \n",
       "96      5              Brilliant   \n",
       "97      5              Excellent   \n",
       "98      5            Pretty good   \n",
       "99      5  Mind-blowing purchase   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Just go for it.\\nThis phone is really amazing....  \n",
       "96  A wort full value for money decision it’s . Si...  \n",
       "97  A perfect phone and a good battery super camer...  \n",
       "98  I've used this phone for over a month now and ...  \n",
       "99  Excellent camera 📸 And Display touching very N...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so lets extract all the data having by using for loop\n",
    "for i in range (0,13):\n",
    "    for a in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        Rating.append(a.text)\n",
    "    for b in driver.find_elements_by_xpath(\"//div[@class= 't-ZTKy']\"):\n",
    "        Full_review.append(b.text)\n",
    "    for c in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        Review_summary.append(c.text)\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class= '_1LKTO3'][2]\").click()\n",
    "    \n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class= '_1LKTO3']\").click()\n",
    "    time.sleep(15)\n",
    "    \n",
    "    \n",
    "#Store the data in a dataframe.    \n",
    "dictionnary = {\n",
    "   'Rating': Rating[:100], \n",
    "   'Review Summary':Review_summary[:100], \n",
    "   'Full Review':Full_review[:100],\n",
    "\n",
    "}\n",
    "iphone = pd.DataFrame(data=dictionnary) \n",
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be0e6b9",
   "metadata": {},
   "source": [
    "## Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "06dcfa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "#let's open the webpage through over web driver \n",
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4c4567c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//button[@class= '_2KpZ6l _2doB4z']\").click()\n",
    "search = driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]//input')\n",
    "search.clear()\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "search_button = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2d6dd0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "description = []\n",
    "price = []\n",
    "discount = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "930648ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range (3):\n",
    "    brand_tags = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    desc_tags = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]//a')\n",
    "    price_tags = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    discount_tags = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    for i in desc_tags:\n",
    "        description.append(i.text)\n",
    "    \n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    \n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//a[@class= '_1LKTO3'][2]\").click()\n",
    "    \n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//a[@class= '_1LKTO3']\").click()\n",
    "    time.sleep(15)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d72dec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Field Care</td>\n",
       "      <td>Casual Flat Sole Fashionable Trendy Outdoor Co...</td>\n",
       "      <td>₹899</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 L Perf Puma White-Puma Whi Sneak...</td>\n",
       "      <td>₹2,749</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹158</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>corsac</td>\n",
       "      <td>STYLISH MENS BLACK SNEAKER Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Casual , Partywear Sneakers Shoes For Men's An...</td>\n",
       "      <td>₹249</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Noah Sneakers For Men</td>\n",
       "      <td>₹3,769</td>\n",
       "      <td>16% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>CH-527 Trendy Star Perfect Casuals Sneakers Fo...</td>\n",
       "      <td>₹273</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RODDICK SHOES</td>\n",
       "      <td>Fashion Outdoor Canvas Casual Light Weight Lac...</td>\n",
       "      <td>₹430</td>\n",
       "      <td>56% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Flatheads</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,445</td>\n",
       "      <td>38% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand                                        Description   Price  \\\n",
       "0      Field Care  Casual Flat Sole Fashionable Trendy Outdoor Co...    ₹899   \n",
       "1            PUMA  Puma Smash v2 L Perf Puma White-Puma Whi Sneak...  ₹2,749   \n",
       "2        URBANBOX                          Sneakers Sneakers For Men    ₹158   \n",
       "3          corsac        STYLISH MENS BLACK SNEAKER Sneakers For Men    ₹449   \n",
       "4      D-SNEAKERZ  Casual , Partywear Sneakers Shoes For Men's An...    ₹249   \n",
       "..            ...                                                ...     ...   \n",
       "95           PUMA                              Noah Sneakers For Men  ₹3,769   \n",
       "96         Chevit  CH-527 Trendy Star Perfect Casuals Sneakers Fo...    ₹273   \n",
       "97      DUNKASTON                                   Sneakers For Men    ₹399   \n",
       "98  RODDICK SHOES  Fashion Outdoor Canvas Casual Light Weight Lac...    ₹430   \n",
       "99      Flatheads                                   Sneakers For Men  ₹2,445   \n",
       "\n",
       "   Discount  \n",
       "0   55% off  \n",
       "1   31% off  \n",
       "2   84% off  \n",
       "3   70% off  \n",
       "4   62% off  \n",
       "..      ...  \n",
       "95  16% off  \n",
       "96  65% off  \n",
       "97  73% off  \n",
       "98  56% off  \n",
       "99  38% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionnary = {\n",
    "   'Brand': brand[:100], \n",
    "   'Description':description[::2][:100], \n",
    "   'Price':price[:100],\n",
    "   'Discount':discount[:100]\n",
    "\n",
    "}\n",
    "sneakers= pd.DataFrame(data=dictionnary) \n",
    "sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b60bc7",
   "metadata": {},
   "source": [
    "## Q7: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bca54229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's open the webpage through our webdriver\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "11620f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's filter price limit “Rs. 7149 to Rs. 14099 ”\n",
    "price_filter= driver.find_elements_by_xpath(\"//div[@class= 'common-checkboxIndicator']\")\n",
    "price_filter[14].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4935042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's filter colour of shoes 'black'.\n",
    "price_filter= driver.find_elements_by_xpath(\"//div[@class= 'common-checkboxIndicator']\")\n",
    "price_filter[17].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f64fa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "description = []\n",
    "price = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "193316d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe_Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIRFORCE 1'07 LV8 EMB Sneakers</td>\n",
       "      <td>Rs. 8725Rs. 9695(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR FORCE 1 '07 LV8 Sneakers</td>\n",
       "      <td>Rs. 8725Rs. 9695(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA Hoops</td>\n",
       "      <td>Men Basketball Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Men Printed Trekking Shoes</td>\n",
       "      <td>Rs. 11599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Leather Monks</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DAVINCHI</td>\n",
       "      <td>Men Textured Formal Leather Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women KarlieKlossX9000 Running</td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Shoe_Brand                          Description                      Price\n",
       "0         Nike       AIRFORCE 1'07 LV8 EMB Sneakers  Rs. 8725Rs. 9695(10% OFF)\n",
       "1         Nike         AIR FORCE 1 '07 LV8 Sneakers  Rs. 8725Rs. 9695(10% OFF)\n",
       "2         ALDO            Men Leather Driving Shoes                  Rs. 12999\n",
       "3     Skechers           Men Max Cushioning Running  Rs. 7649Rs. 8999(15% OFF)\n",
       "4     Skechers                    Men Walking Shoes  Rs. 7649Rs. 8999(15% OFF)\n",
       "..         ...                                  ...                        ...\n",
       "95  PUMA Hoops                 Men Basketball Shoes                   Rs. 7999\n",
       "96        FILA           Men Printed Trekking Shoes                  Rs. 11599\n",
       "97     Bugatti                    Men Leather Monks                   Rs. 8999\n",
       "98    DAVINCHI  Men Textured Formal Leather Loafers                   Rs. 8990\n",
       "99      ADIDAS       Women KarlieKlossX9000 Running                  Rs. 13999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (0,3):\n",
    "    for a in driver.find_elements_by_xpath(\"//h3[@class='product-brand']\"):\n",
    "        brand.append(a.text)\n",
    "    for b in driver.find_elements_by_xpath(\"//h4[@class='product-product']\"):\n",
    "        description.append(b.text)\n",
    "    for c in driver.find_elements_by_xpath(\"//div[@class='product-price']\"):\n",
    "        price.append(c.text)\n",
    "    \n",
    "    \n",
    "dictionnary = {\n",
    "   'Shoe_Brand': brand[:100], \n",
    "   'Description':description[:100], \n",
    "   'Price':price[:100],\n",
    "\n",
    "}\n",
    "shoes = pd.DataFrame(data=dictionnary) \n",
    "shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d07f65",
   "metadata": {},
   "source": [
    "## Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”.scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:1. Title,2. Ratings,3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0ed973be",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7172badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for laptop search bar\n",
    "# Creating object of the search bar by finding it through Class name\n",
    "search_bar_fk=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "\n",
    "# Clearing the bar if there is any text in it\n",
    "search_bar_fk.clear()\n",
    "\n",
    "# Sending required product to the search bar\n",
    "search_bar_fk.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bf7aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_id('nav-search-submit-button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47c3cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_button= driver.find_elements_by_xpath(\"//a[@class= 'a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text == \"Intel Core i7\"and \"Intel Core i9\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3889b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "title= []\n",
    "price= []\n",
    "ratings= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "575e12b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 14 inches Ultra-Light Intel Evo 11th G...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>88,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>93,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.6</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Acer Predator Helios 300 11th Gen Intel Core i...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LG Gram 16 inches Intel Evo 11th Gen Core i7 U...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>89,611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microsoft Surface Studio 14.4 inches Touchscre...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3,73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion 11th Gen Intel Core i7 Processor 1...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion x360 11th Gen Intel Core i7 14 inc...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title Ratings     Price\n",
       "0  LG Gram 14 inches Ultra-Light Intel Evo 11th G...     4.4    88,499\n",
       "1  LG Gram Intel Evo 11th Gen Core i7 17 inches U...     4.5    93,999\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...     4.5    57,490\n",
       "3  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....     4.6    86,990\n",
       "4  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...     4.5    86,990\n",
       "5  Acer Predator Helios 300 11th Gen Intel Core i...     5.0  1,69,990\n",
       "6  LG Gram 16 inches Intel Evo 11th Gen Core i7 U...     4.4    89,611\n",
       "7  Microsoft Surface Studio 14.4 inches Touchscre...     4.3  3,73,999\n",
       "8  HP Pavilion 11th Gen Intel Core i7 Processor 1...     4.3    89,990\n",
       "9  HP Pavilion x360 11th Gen Intel Core i7 14 inc...     3.7    86,990"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars = driver.find_elements_by_class_name('a-icon-alt')\n",
    "\n",
    "for i in stars:\n",
    "    ratings.append(i.get_attribute('innerHTML').split(' ')[0])\n",
    "\n",
    "\n",
    "for j in driver.find_elements_by_xpath(\"//span[@class= 'a-size-medium a-color-base a-text-normal']\"):\n",
    "    title.append(j.text)\n",
    "        \n",
    "for l in driver.find_elements_by_xpath(\"//span[@class= 'a-price-whole']\"):\n",
    "    price.append(l.text)\n",
    " \n",
    " #Store the data in a dataframe.   \n",
    "dictionnary = {\n",
    "   'Title': title[:10], \n",
    "   'Ratings':ratings[:10], \n",
    "   'Price':price[:10],\n",
    "\n",
    "}\n",
    "laptops = pd.DataFrame(data=dictionnary)\n",
    "laptops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8138d31",
   "metadata": {},
   "source": [
    "## Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8dbc7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.ambitionbox.com/'\n",
    "#let's open the webpage through over web driver \n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cee51216",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_search = driver.find_element_by_xpath('//*[@id=\"headerWrapper\"]/nav/nav/a[6]')\n",
    "job_search.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6e59faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "jobs= driver.find_element_by_xpath('//*[@id=\"jobs-typeahead\"]/span/input')\n",
    "jobs.clear()\n",
    "jobs.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2f27b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath('//button[@class=\"ab_btn search-btn round\"]')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a48d3cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_elements_by_xpath('//p[@class=\"body-medium text-capitalize undefined\"]')\n",
    "location[1].click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3620e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job location bar\n",
    "loca= driver.find_element_by_xpath('//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "loca.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6280eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath('//*[@id=\"filters-row\"]/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1468591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name=[]\n",
    "days_ago_job_posted=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "046120cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>No of days ago job posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tech Mahindra Ltd</td>\n",
       "      <td>20d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>23d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>27d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>5d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft India (R and D) Pvt Ltd</td>\n",
       "      <td>2mon ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Company_name No of days ago job posted Rating\n",
       "0      GENPACT India Private Limited                    1d ago    4.0\n",
       "1      GENPACT India Private Limited                    6d ago    4.0\n",
       "2                  Tech Mahindra Ltd                   20d ago    3.7\n",
       "3      GENPACT India Private Limited                   23d ago    4.0\n",
       "4                   HCL Technologies                   27d ago    3.8\n",
       "5                              Zyoin                    5d ago    4.1\n",
       "6  Newgen Software Technologies Ltd.                    7d ago    3.5\n",
       "7         Pitney Bowes India Pvt Ltd                  1mon ago    4.2\n",
       "8                  JK Technosoft Ltd                   16d ago    3.6\n",
       "9  Microsoft India (R and D) Pvt Ltd                  2mon ago    4.3"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so lets extract all the data having by using for loop\n",
    "for i in range(10):\n",
    "    for a in driver.find_elements_by_xpath(\"//p[@class='company body-medium']\"):\n",
    "        company_name.append(a.text)\n",
    "        company_name=company_name[:10]\n",
    "        \n",
    "        \n",
    "    for b in driver.find_elements_by_xpath(\"//span[@class='body-small-l']\"):\n",
    "        days_ago_job_posted.append(b.text)\n",
    "    \n",
    "        \n",
    "    for c in driver.find_elements_by_xpath(\"//span[@class='body-small']\"):\n",
    "        Rating.append(c.text)\n",
    "        rating=driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "    for i in range(0,len(rating),2):\n",
    "        Rating.append(rating[i].text)\n",
    "        Rating=Rating[:10]   \n",
    " \n",
    "\n",
    " #Store the data in a dataframe. \n",
    "dictionnary = {\n",
    "   'Company_name': company_name[:10], \n",
    "   'No of days ago job posted':days_ago_job_posted[::2][:10], \n",
    "   'Rating':Rating,\n",
    "\n",
    "}\n",
    "company= pd.DataFrame(data=dictionnary) \n",
    "company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc41ea",
   "metadata": {},
   "source": [
    "## Q10: Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6fb5c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1fc859e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath('//*[@id=\"headerWrapper\"]/nav/nav/a[4]')\n",
    "search_button.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "208696f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding element for job search bar\n",
    "jobs= driver.find_element_by_xpath('//*[@id=\"jobProfileSearchbox\"]')\n",
    "jobs.clear()\n",
    "jobs.send_keys('Data Scientist')\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath('//div[@class=\"suggestion_wrap tt-suggestion tt-selectable\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ecc5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "company_name= []\n",
    "total_salary_record= []\n",
    "average_salary= []\n",
    "minimum_salary=[]\n",
    "maximum_salary=[]\n",
    "experience_required= []\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='company-info']//a\"):\n",
    "    company_name.append(i.text)\n",
    "\n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[1]/div/div/div[1]/span'):\n",
    "        total_salary_record.append(i.text)\n",
    "        total_salary_record2=driver.find_elements_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[3]/div[2]/div[2]/div[1]/div/div/div[1]/span')\n",
    "    for i in range(0,len(total_salary_record2),2):\n",
    "        total_salary_record.append(total_salary_record2[i].text)\n",
    "        total_salary_record=total_salary_record[:10]   \n",
    "        \n",
    "    for i in driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]'):\n",
    "        average_salary.append(i.text)\n",
    "        average_salary2=driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "    for i in range(0,len(average_salary2),2):\n",
    "        average_salary.append(average_salary2[i].text)\n",
    "        average_salary=average_salary[:10]  \n",
    "    \n",
    "    \n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]'):\n",
    "        minimum_salary.append(i.text)\n",
    "        minimum_salary2=driver.find_elements_by_xpath('//div[@class=\"value body-medium\"]')\n",
    "    for i in range(0,len(minimum_salary2),2):\n",
    "        minimum_salary.append(minimum_salary2[i].text)\n",
    "        minimum_salary= minimum_salary[:10]  \n",
    "    \n",
    "    \n",
    "    for i in driver.find_elements_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[3]/div[2]/div[1]/div[2]/div/div[2]/div[2]'):\n",
    "        maximum_salary.append(i.text)\n",
    "        maximum_salary2=driver.find_elements_by_xpath('//*[@id=\"salaries\"]/main/section[1]/div[2]/div[3]/div[2]/div[2]/div[2]/div/div[2]/div[2]')\n",
    "    for i in range(0,len(maximum_salary2),2):\n",
    "        maximum_salary.append(maximum_salary2[i].text)\n",
    "        maximum_salary=maximum_salary[:10]  \n",
    "    \n",
    "        \n",
    "    for i in driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]'):\n",
    "        experience_required.append(i.text.replace('\\n','').split(\". \")[1])\n",
    "        experience_required2=driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "    for i in range(0,len(experience_required2),2):\n",
    "        experience_required.append(experience_required2[i].text.replace('\\n','').split(\". \")[1])\n",
    "        experience_required=experience_required[:10]  \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "420471ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>total_salary_record</th>\n",
       "      <th>average_salary</th>\n",
       "      <th>minimum_salary</th>\n",
       "      <th>maximum salary</th>\n",
       "      <th>experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 22.4L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company_name   total_salary_record average_salary  \\\n",
       "0                   Walmart  based on 11 salaries        ₹ 29.7L   \n",
       "1                  Ab Inbev  based on 31 salaries        ₹ 20.5L   \n",
       "2              Reliance Jio  based on 11 salaries        ₹ 18.9L   \n",
       "3                        ZS  based on 31 salaries        ₹ 15.9L   \n",
       "4                     Optum  based on 11 salaries        ₹ 15.4L   \n",
       "5         Fractal Analytics  based on 31 salaries        ₹ 15.1L   \n",
       "6           Tiger Analytics  based on 11 salaries        ₹ 14.8L   \n",
       "7              UnitedHealth  based on 31 salaries        ₹ 14.0L   \n",
       "8                   Verizon  based on 11 salaries        ₹ 12.7L   \n",
       "9  Ganit Business Solutions  based on 31 salaries        ₹ 12.4L   \n",
       "\n",
       "  minimum_salary maximum salary experience required  \n",
       "0        ₹ 25.0L        ₹ 35.0L           3 yrs exp  \n",
       "1        ₹ 35.0L        ₹ 25.5L         3-4 yrs exp  \n",
       "2        ₹ 15.0L        ₹ 35.0L           4 yrs exp  \n",
       "3        ₹ 25.5L        ₹ 25.5L           2 yrs exp  \n",
       "4         ₹ 5.6L        ₹ 35.0L         3-4 yrs exp  \n",
       "5        ₹ 26.2L        ₹ 25.5L         2-4 yrs exp  \n",
       "6         ₹ 9.8L        ₹ 35.0L         2-4 yrs exp  \n",
       "7        ₹ 20.0L        ₹ 25.5L         2-4 yrs exp  \n",
       "8        ₹ 11.0L        ₹ 35.0L           4 yrs exp  \n",
       "9        ₹ 22.4L        ₹ 25.5L           4 yrs exp  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Store the data in a dataframe.\n",
    "dictionnary = {\n",
    "   'company_name': company_name[:10], \n",
    "   'total_salary_record':total_salary_record[:10], \n",
    "   'average_salary':average_salary[:10],\n",
    "   'minimum_salary':minimum_salary[:10],\n",
    "   'maximum salary':maximum_salary[:10],\n",
    "   'experience required':experience_required[:10]\n",
    "}\n",
    "jobs = pd.DataFrame(data=dictionnary) \n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20067883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43385065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
